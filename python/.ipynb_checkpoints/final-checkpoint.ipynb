{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "italic-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"aa\": [\"aa\", \"alcoholic anonymous\"],\n",
    "    \"acquisition\": [\"acquisition\"],\n",
    "    \"addiction\": [\"addiction\"],\n",
    "    \"alcohol\" : [\"alcohol\", \"henny\", \"henessy\", \"vodka\"],\n",
    "    \"antidepressants\": [\"antidepressants\"],\n",
    "    \"anxiolytics\": [\"anxiolytics\"],\n",
    "    \"cannabis\": [\"cannabis\"],\n",
    "    \"chem_and_bio\": [\"chem_and_bio\"],\n",
    "    \"comfort\": [\"comfort\"],\n",
    "    \"counseling\": [\"counseling\"],\n",
    "    \"darknet\": [\"darknet\"],\n",
    "    \"delivery\": [\"delivery\"],\n",
    "    \"depressants\": [\"depressants\"],\n",
    "    \"discomfort\": [\"discomfort\"],\n",
    "    \"drug\": [\"drug\"],\n",
    "    \"drug_paraphrenalia\": [\"paraphrenalia\"],\n",
    "    \"drug_quantity\": [\"drug quantity\"],\n",
    "    \"drug_users\": [\"drug users\"],\n",
    "    \"drunk\": [\"drunk\"],\n",
    "    \"effects\": [\"effects\"],\n",
    "    \"energetic\": [\"energetic\"],\n",
    "    \"euphoria\": [\"euphoria\", \"euphoric\"],\n",
    "    \"finance\": [\"finance\"],\n",
    "    \"hallucinogens\": [\"hallucinogens\", \"mushrooms\", \"lsd\"],\n",
    "    \"health\": [\"health\"],\n",
    "    \"hospital\": [\"hospital\"],\n",
    "    \"idu\": [\"idu\"],\n",
    "    \"increased\": [\"increased\"],\n",
    "    \"legal\": [\"legal\"],\n",
    "    \"locations\": [\"locations\", \"street corner\"],\n",
    "    \"meditation\": [\"meditation\"],\n",
    "    \"mental\": [\"mental\"],\n",
    "    \"nooptropics\": [\"nooptropics\", \"nootropics\"],\n",
    "    \"numbness\": [\"numbness\"],\n",
    "    \"opioids\": [\"opioids\", \"oxycodone\", \"oxy\", \"heroin\", \"morphine\"],\n",
    "    \"oral\": [\"oral\", \"popping\"],\n",
    "    \"overdose\": [\"overdose\", \"OD\"],\n",
    "    \"physical\": [\"physical\"],\n",
    "    \"physical_withdrawal_symptoms\": [\"physical withdrawal symptoms\"],\n",
    "    \"prescription\": [\"prescription\"],\n",
    "    \"psychedelic\": [\"psychedelic\"],\n",
    "    \"pschological_withdrawal_symptoms\": [\"pschological withdrawal symptoms\"],\n",
    "    \"quitting\": [\"quitting\"],\n",
    "    \"recovery\": [\"recovery\"],\n",
    "    \"recovery_support\": [\"recovery support\"],\n",
    "    \"rehab\" : [\"rehab\", \"rehabilitation\"],\n",
    "    \"relapse\": [\"relapse\"],\n",
    "    \"seizure\": [\"seizure\"],\n",
    "    \"smoking\": [\"smoking\", \"cigarette\", \"cigs\", \"squares\"],\n",
    "    \"stimulants\": [\"stimulants\", \"stims\"],\n",
    "    \"street\": [\"street\"],\n",
    "    \"supplements\": [\"supplements\"],\n",
    "    \"therapy\": [\"therapy\"],\n",
    "    \"tobacco\": [\"tobacco\"],\n",
    "    \"tolerance\": [\"tolerance\"],\n",
    "    \"using\": [\"using\", \"shooting\"],\n",
    "    \"withdrawal\": [\"withdrawal\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stylish-boost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>alcoholic anonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acquisition</td>\n",
       "      <td>acquisit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>addiction</td>\n",
       "      <td>addict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alcohol</td>\n",
       "      <td>alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tobacco</td>\n",
       "      <td>tobacco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tolerance</td>\n",
       "      <td>toler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>using</td>\n",
       "      <td>shoot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>withdrawal</td>\n",
       "      <td>withdraw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category              term\n",
       "0            aa                aa\n",
       "1            aa  alcoholic anonym\n",
       "0   acquisition          acquisit\n",
       "0     addiction            addict\n",
       "0       alcohol           alcohol\n",
       "..          ...               ...\n",
       "0       tobacco           tobacco\n",
       "0     tolerance             toler\n",
       "0         using               use\n",
       "1         using             shoot\n",
       "0    withdrawal          withdraw\n",
       "\n",
       "[78 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Stemmer\n",
    "import pandas as pd\n",
    "\n",
    "# Use english stemmer as all keywords are in english\n",
    "stemmer = Stemmer.Stemmer('en')\n",
    "\n",
    "dfs = []\n",
    "for key, values in categories.items():\n",
    "    words = pd.DataFrame({'category': key, 'term': stemmer.stemWords(values)})\n",
    "    dfs.append(words)\n",
    "    \n",
    "terms_df = pd.concat(dfs)\n",
    "terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "separate-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>search_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500998000101011456</td>\n",
       "      <td>an oxycodone prescription is a dangerous thing...</td>\n",
       "      <td>oxycodone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500995581342216192</td>\n",
       "      <td>trust me they are not bankrupt they claim ban...</td>\n",
       "      <td>oxycodone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500995007909535744</td>\n",
       "      <td>Large quantity of oxycodone seized during Kaml...</td>\n",
       "      <td>oxycodone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500995004856107008</td>\n",
       "      <td>Large quantity of oxycodone seized during Kaml...</td>\n",
       "      <td>oxycodone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500995002985373696</td>\n",
       "      <td>Large quantity of oxycodone seized during Kaml...</td>\n",
       "      <td>oxycodone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>1514640367592914944</td>\n",
       "      <td>It will only cost you 2 Vicodin, an 8 ball an...</td>\n",
       "      <td>Vicodin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>1514632415427321856</td>\n",
       "      <td></td>\n",
       "      <td>Vicodin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>1514630579651764224</td>\n",
       "      <td>I have done two brilliant things i...</td>\n",
       "      <td>Vicodin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>1514625270568869888</td>\n",
       "      <td>“Please do not discuss other pills outside of ...</td>\n",
       "      <td>Vicodin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>1514624946001096704</td>\n",
       "      <td>You know things are going bad when I’m on the ...</td>\n",
       "      <td>Vicodin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2638 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0     1500998000101011456  an oxycodone prescription is a dangerous thing...   \n",
       "1     1500995581342216192   trust me they are not bankrupt they claim ban...   \n",
       "2     1500995007909535744  Large quantity of oxycodone seized during Kaml...   \n",
       "3     1500995004856107008  Large quantity of oxycodone seized during Kaml...   \n",
       "4     1500995002985373696  Large quantity of oxycodone seized during Kaml...   \n",
       "...                   ...                                                ...   \n",
       "2633  1514640367592914944   It will only cost you 2 Vicodin, an 8 ball an...   \n",
       "2634  1514632415427321856                                                      \n",
       "2635  1514630579651764224              I have done two brilliant things i...   \n",
       "2636  1514625270568869888  “Please do not discuss other pills outside of ...   \n",
       "2637  1514624946001096704  You know things are going bad when I’m on the ...   \n",
       "\n",
       "     search_term  \n",
       "0      oxycodone  \n",
       "1      oxycodone  \n",
       "2      oxycodone  \n",
       "3      oxycodone  \n",
       "4      oxycodone  \n",
       "...          ...  \n",
       "2633     Vicodin  \n",
       "2634     Vicodin  \n",
       "2635     Vicodin  \n",
       "2636     Vicodin  \n",
       "2637     Vicodin  \n",
       "\n",
       "[2638 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_db_path = \"../database.json\"\n",
    "\n",
    "df = pd.read_json(tweet_db_path)\n",
    "\n",
    "# filtering out \"at's\" and http links\n",
    "for index, row in df.iterrows():\n",
    "    filtered_tweet_words = []\n",
    "\n",
    "    for word in row[\"text\"].split(' '):\n",
    "        if word.startswith(\"@\") and len(word) > 1:\n",
    "            word = \"\"\n",
    "        elif word.startswith(\"http\"):\n",
    "            word = \"\"\n",
    "        filtered_tweet_words.append(word)\n",
    "    tweet = \" \".join(filtered_tweet_words)\n",
    "    df.at[index, \"text\"] = tweet\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "particular-monster",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/.miniconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:1322: UserWarning: Upper case characters found in vocabulary while 'lowercase' is True. These entries will not be matched with any documents\n",
      "  warnings.warn(\n",
      "/home/nico/.miniconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>alcoholic anonym</th>\n",
       "      <th>acquisit</th>\n",
       "      <th>addict</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>henni</th>\n",
       "      <th>henessi</th>\n",
       "      <th>vodka</th>\n",
       "      <th>antidepress</th>\n",
       "      <th>anxiolyt</th>\n",
       "      <th>...</th>\n",
       "      <th>stimul</th>\n",
       "      <th>stim</th>\n",
       "      <th>street</th>\n",
       "      <th>supplement</th>\n",
       "      <th>therapi</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>toler</th>\n",
       "      <th>use</th>\n",
       "      <th>shoot</th>\n",
       "      <th>withdraw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  alcoholic anonym  acquisit  addict  alcohol  henni  henessi  vodka  \\\n",
       "0   0                 0         0       0        0      0        0      0   \n",
       "1   0                 0         0       0        0      0        0      0   \n",
       "2   0                 0         0       0        0      0        0      0   \n",
       "3   0                 0         0       0        0      0        0      0   \n",
       "4   0                 0         0       0        0      0        0      0   \n",
       "\n",
       "   antidepress  anxiolyt  ...  stimul  stim  street  supplement  therapi  \\\n",
       "0            0         0  ...       0     0       0           0        0   \n",
       "1            0         0  ...       0     0       0           0        0   \n",
       "2            0         0  ...       0     0       0           0        0   \n",
       "3            0         0  ...       0     0       0           0        0   \n",
       "4            0         0  ...       0     0       0           0        0   \n",
       "\n",
       "   tobacco  toler  use  shoot  withdraw  \n",
       "0        0      0    0      0         0  \n",
       "1        0      0    0      0         0  \n",
       "2        0      0    0      0         0  \n",
       "3        0      0    0      0         0  \n",
       "4        0      0    0      0         0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stemmer = Stemmer.Stemmer('en')\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: stemmer.stemWords([w for w in analyzer(doc)])\n",
    "\n",
    "term_list = list(terms_df.term)\n",
    "\n",
    "vectorizer = StemmedCountVectorizer(binary = True, vocabulary = term_list)\n",
    "fitted = vectorizer.fit_transform(df.text)\n",
    "words_df = pd.DataFrame(fitted.toarray(), columns = vectorizer.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "helpful-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category: aa\n",
      "stems: ['aa', 'alcoholic anonym']\n",
      "\n",
      "category: acquisition\n",
      "stems: ['acquisit']\n",
      "\n",
      "category: addiction\n",
      "stems: ['addict']\n",
      "\n",
      "category: alcohol\n",
      "stems: ['alcohol', 'henni', 'henessi', 'vodka']\n",
      "\n",
      "category: antidepressants\n",
      "stems: ['antidepress']\n",
      "\n",
      "category: anxiolytics\n",
      "stems: ['anxiolyt']\n",
      "\n",
      "category: cannabis\n",
      "stems: ['cannabi']\n",
      "\n",
      "category: chem_and_bio\n",
      "stems: ['chem_and_bio']\n",
      "\n",
      "category: comfort\n",
      "stems: ['comfort']\n",
      "\n",
      "category: counseling\n",
      "stems: ['counsel']\n",
      "\n",
      "category: darknet\n",
      "stems: ['darknet']\n",
      "\n",
      "category: delivery\n",
      "stems: ['deliveri']\n",
      "\n",
      "category: depressants\n",
      "stems: ['depress']\n",
      "\n",
      "category: discomfort\n",
      "stems: ['discomfort']\n",
      "\n",
      "category: drug\n",
      "stems: ['drug']\n",
      "\n",
      "category: drug_paraphrenalia\n",
      "stems: ['paraphrenalia']\n",
      "\n",
      "category: drug_quantity\n",
      "stems: ['drug quant']\n",
      "\n",
      "category: drug_users\n",
      "stems: ['drug us']\n",
      "\n",
      "category: drunk\n",
      "stems: ['drunk']\n",
      "\n",
      "category: effects\n",
      "stems: ['effect']\n",
      "\n",
      "category: energetic\n",
      "stems: ['energet']\n",
      "\n",
      "category: euphoria\n",
      "stems: ['euphoria', 'euphor']\n",
      "\n",
      "category: finance\n",
      "stems: ['financ']\n",
      "\n",
      "category: hallucinogens\n",
      "stems: ['hallucinogen', 'mushroom', 'lsd']\n",
      "\n",
      "category: health\n",
      "stems: ['health']\n",
      "\n",
      "category: hospital\n",
      "stems: ['hospit']\n",
      "\n",
      "category: idu\n",
      "stems: ['idu']\n",
      "\n",
      "category: increased\n",
      "stems: ['increas']\n",
      "\n",
      "category: legal\n",
      "stems: ['legal']\n",
      "\n",
      "category: locations\n",
      "stems: ['locat', 'street corn']\n",
      "\n",
      "category: meditation\n",
      "stems: ['medit']\n",
      "\n",
      "category: mental\n",
      "stems: ['mental']\n",
      "\n",
      "category: nooptropics\n",
      "stems: ['nooptrop', 'nootrop']\n",
      "\n",
      "category: numbness\n",
      "stems: ['numb']\n",
      "\n",
      "category: opioids\n",
      "stems: ['opioid', 'oxycodon', 'oxi', 'heroin', 'morphin']\n",
      "\n",
      "category: oral\n",
      "stems: ['oral', 'pop']\n",
      "\n",
      "category: overdose\n",
      "stems: ['overdos', 'OD']\n",
      "\n",
      "category: physical\n",
      "stems: ['physic']\n",
      "\n",
      "category: physical_withdrawal_symptoms\n",
      "stems: ['physical withdrawal symptom']\n",
      "\n",
      "category: prescription\n",
      "stems: ['prescript']\n",
      "\n",
      "category: pschological_withdrawal_symptoms\n",
      "stems: ['pschological withdrawal symptom']\n",
      "\n",
      "category: psychedelic\n",
      "stems: ['psychedel']\n",
      "\n",
      "category: quitting\n",
      "stems: ['quit']\n",
      "\n",
      "category: recovery\n",
      "stems: ['recoveri']\n",
      "\n",
      "category: recovery_support\n",
      "stems: ['recovery support']\n",
      "\n",
      "category: rehab\n",
      "stems: ['rehab', 'rehabilit']\n",
      "\n",
      "category: relapse\n",
      "stems: ['relaps']\n",
      "\n",
      "category: seizure\n",
      "stems: ['seizur']\n",
      "\n",
      "category: smoking\n",
      "stems: ['smoke', 'cigarett', 'cig', 'squar']\n",
      "\n",
      "category: stimulants\n",
      "stems: ['stimul', 'stim']\n",
      "\n",
      "category: street\n",
      "stems: ['street']\n",
      "\n",
      "category: supplements\n",
      "stems: ['supplement']\n",
      "\n",
      "category: therapy\n",
      "stems: ['therapi']\n",
      "\n",
      "category: tobacco\n",
      "stems: ['tobacco']\n",
      "\n",
      "category: tolerance\n",
      "stems: ['toler']\n",
      "\n",
      "category: using\n",
      "stems: ['use', 'shoot']\n",
      "\n",
      "category: withdrawal\n",
      "stems: ['withdraw']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for category_name, rows in terms_df.groupby('category'):\n",
    "    terms = list(rows['term'])\n",
    "    print(f\"category: {category_name}\\nstems: {terms}\\n\")\n",
    "\n",
    "    df[category_name] = words_df[terms].any(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pleasant-briefing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 501st tweet in the list contains one instance of the word \"Cannabis\", capitalized\n",
    "df['cannabis'][501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At the very least reschedule!\\n\\nAccording to the DEAs \"science\" the following drugs are all LESS dangerous than Cannabis &amp; Peyote:\\n\\nCocaine\\nFentanyl\\nMeth\\nMethadone\\nOxycodone  '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "premium-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im too drunk rn but I need 5 more shots with oxycodone'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweet we're using as an example\n",
    "test_tweet = df.at[123, \"text\"]\n",
    "test_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "marine-flash",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     l \u001b[38;5;241m=\u001b[39m labels[i]\n\u001b[1;32m     28\u001b[0m     s \u001b[38;5;241m=\u001b[39m scores[i]\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, index \u001b[38;5;129;01min\u001b[39;00m row[\u001b[38;5;241m3\u001b[39m:]:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# if i > 0:\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#     if data[i]:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#         data[i] = scores[2]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(\"\\n\")\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "# Then, perform sentiment analysis on the tweets to figure out if there is a\n",
    "# correlation between these keywords (from DUI) and a positive vs negative\n",
    "# sentiment\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "pretrained_model = open(\"pretrained_model\").read()\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
    "\n",
    "labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "data = {}\n",
    "for index, row in df.head(5).iterrows():\n",
    "#     print(row[\"text\"])\n",
    "    # print(row[3:])\n",
    "    encoded_tweet = tokenizer(row[\"text\"], return_tensors='pt')\n",
    "\n",
    "    output = model(**encoded_tweet)\n",
    "\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    for i in range(len(scores)):\n",
    "        l = labels[i]\n",
    "        s = scores[i]\n",
    "\n",
    "    for i in row[3:]:\n",
    "        print(index)\n",
    "        # if i > 0:\n",
    "        #     if data[i]:\n",
    "        #         data[i] = scores[2]\n",
    "        #     else:\n",
    "        #         data[i] += scores[2]\n",
    "            \n",
    "        # print(l, s)\n",
    "        \n",
    "    # print(\"\\n\")\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-penguin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-house",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
